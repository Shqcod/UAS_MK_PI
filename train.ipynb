{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1342769b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua model berhasil dibuat!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# === Load CSV ===\n",
    "df = pd.read_csv(\"complete_cleaned.csv\")\n",
    "\n",
    "# =================================\n",
    "#  TF-IDF (pakai tokens)\n",
    "# =================================\n",
    "corpus_tokens = df[\"tokens\"].astype(str).tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus_tokens)\n",
    "\n",
    "pickle.dump(vectorizer, open(\"model/tfidf_vectorizer.pkl\", \"wb\"))\n",
    "pickle.dump(tfidf_matrix, open(\"model/tfidf_matrix.pkl\", \"wb\"))\n",
    "\n",
    "# =================================\n",
    "#  BM25 (pakai tokens yg sama)\n",
    "# =================================\n",
    "tokenized_corpus = [doc.split() for doc in corpus_tokens]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "pickle.dump(bm25, open(\"model/bm25.pkl\", \"wb\"))\n",
    "\n",
    "# Simpan data asli\n",
    "pickle.dump(df, open(\"model/news_data.pkl\", \"wb\"))\n",
    "\n",
    "print(\"Semua model berhasil dibuat!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0ca9416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample tokens ===\n",
      "0    ['jakarta', 'kompas', 'com', 'tentara', 'nasio...\n",
      "1    ['jakarta', 'kompas', 'com', 'kepala', 'dinas'...\n",
      "2    ['jakarta', 'kompas', 'com', 'panglima', 'tni'...\n",
      "Name: tokens, dtype: object\n",
      "\n",
      "=== Cek tokens kosong ===\n",
      "Total rows: 1980\n",
      "Empty tokens: 0\n",
      "Blank tokens: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"complete_cleaned.csv\")\n",
    "\n",
    "# Lihat beberapa contoh tokens\n",
    "print(\"=== Sample tokens ===\")\n",
    "print(df[\"tokens\"].head(3))\n",
    "print()\n",
    "\n",
    "# Cek apakah ada tokens yang kosong\n",
    "print(\"=== Cek tokens kosong ===\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Empty tokens: {df['tokens'].isna().sum()}\")\n",
    "print(f\"Blank tokens: {(df['tokens'] == '').sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b5c254b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== After conversion ===\n",
      "Type: <class 'list'>\n",
      "Sample: ['jakarta', 'kompas', 'com', 'tentara', 'nasional', 'indonesia', 'tni', 'angkatan', 'darat', 'ad']\n",
      "\n",
      "=== Tokenized corpus check ===\n",
      "Type: <class 'list'>\n",
      "Sample: ['jakarta', 'kompas', 'com', 'tentara', 'nasional', 'indonesia', 'tni', 'angkatan', 'darat', 'ad']\n",
      "Length: 296\n",
      "\n",
      "✅ Model berhasil dibuat!\n",
      "\n",
      "=== Quick Test ===\n",
      "Query: ['donald', 'trump', 'gaza']\n",
      "Max score: 6.467162573812388\n",
      "Non-zero scores: 1943\n",
      "\n",
      "1. Score: 6.4672\n",
      "   Title: [POPULER GLOBAL] Trump Ingin Membeli Gaza | Tak Ada yang Bisa Mengusir Warga Palestina\n",
      "\n",
      "2. Score: 6.3288\n",
      "   Title: Apa yang Dibicarakan Prabowo dan Trump di KTT Gaza yang Terekam Mikrofon?\n",
      "\n",
      "3. Score: 6.3190\n",
      "   Title: Serba-serbi Prabowo \"Si Pria Tangguh\" Saksikan Trump Teken Perdamaian Gaza\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import ast  # ← PENTING!\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(\"complete_cleaned.csv\")\n",
    "\n",
    "# =================================\n",
    "#  KONVERSI STRING → LIST\n",
    "# =================================\n",
    "# Kolom tokens adalah string representation dari list\n",
    "# Contoh: \"['jakarta', 'kompas', 'com']\"\n",
    "# Kita perlu convert ke list Python yang sebenarnya\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except:\n",
    "        # Jika gagal, coba split biasa\n",
    "        return val.split() if isinstance(val, str) else []\n",
    "\n",
    "df['tokens'] = df['tokens'].apply(safe_literal_eval)\n",
    "\n",
    "# Debug: Cek konversi\n",
    "print(\"=== After conversion ===\")\n",
    "print(f\"Type: {type(df['tokens'].iloc[0])}\")\n",
    "print(f\"Sample: {df['tokens'].iloc[0][:10]}\")\n",
    "print()\n",
    "\n",
    "# =================================\n",
    "#  TF-IDF (join list jadi string)\n",
    "# =================================\n",
    "corpus_tokens_str = df[\"tokens\"].apply(lambda x: ' '.join(x) if isinstance(x, list) else x).tolist()\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus_tokens_str)\n",
    "\n",
    "pickle.dump(vectorizer, open(\"model/tfidf_vectorizer.pkl\", \"wb\"))\n",
    "pickle.dump(tfidf_matrix, open(\"model/tfidf_matrix.pkl\", \"wb\"))\n",
    "\n",
    "# =================================\n",
    "#  BM25 (langsung pakai list)\n",
    "# =================================\n",
    "tokenized_corpus = df['tokens'].tolist()  # Sudah list, tidak perlu split!\n",
    "\n",
    "# Debug\n",
    "print(\"=== Tokenized corpus check ===\")\n",
    "print(f\"Type: {type(tokenized_corpus[0])}\")\n",
    "print(f\"Sample: {tokenized_corpus[0][:10]}\")\n",
    "print(f\"Length: {len(tokenized_corpus[0])}\")\n",
    "print()\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "pickle.dump(bm25, open(\"model/bm25.pkl\", \"wb\"))\n",
    "\n",
    "# Simpan data\n",
    "pickle.dump(df, open(\"model/news_data.pkl\", \"wb\"))\n",
    "\n",
    "print(\"✅ Model berhasil dibuat!\")\n",
    "\n",
    "# =================================\n",
    "#  TEST LANGSUNG\n",
    "# =================================\n",
    "print(\"\\n=== Quick Test ===\")\n",
    "test_query = ['donald', 'trump', 'gaza']\n",
    "scores = bm25.get_scores(test_query)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Max score: {scores.max()}\")\n",
    "print(f\"Non-zero scores: {(scores > 0).sum()}\")\n",
    "\n",
    "top_idx = scores.argsort()[::-1][:3]\n",
    "for i, idx in enumerate(top_idx):\n",
    "    print(f\"\\n{i+1}. Score: {scores[idx]:.4f}\")\n",
    "    print(f\"   Title: {df.loc[idx, 'title']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uasmkpi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
